# AI Prompts - Professional Markdown Toolkit

*Collection of effective AI prompts used in this project*

## Project Context Prompts

### Session Start Prompt
```
I'm working on the Professional Markdown Toolkit project. Please read the following context carefully:

**PROJECT**: Professional Markdown Toolkit - Production-ready Obsidian vault management and markdown processing tools
**REPOSITORY**: https://github.com/ronanchris/profession-markdown-toolkit.git
**CURRENT STATUS**: Production ready + Notion import tools + Portable distribution + Plan-Driven Session Management System

[Full entrance prompt from SESSION-ENTRANCE-PROMPT.md]
```

### Problem-Solving Prompt
```
We're working on [specific issue]. Here's the context:
- Current situation: [describe current state]
- Desired outcome: [describe goal]
- Constraints: [any limitations]
- Previous attempts: [what's been tried]

Please analyze this systematically and suggest a surgical approach.
```

### Code Review Prompt
```
Please review this [script/code] for:
1. Security vulnerabilities
2. Backup functionality preservation
3. Cross-platform compatibility
4. Error handling completeness
5. Professional-grade user experience

Maintain enterprise-ready standards.
```

## Specialized Prompts

### Notion Import Troubleshooting
```
I have a Notion import that's failing. The document is [size] with [characteristics]. 
Please analyze the failure pattern and suggest specific fixes using our toolkit:
- unicode_cleaner.py for encoding issues
- wikilink_converter.py for link problems
- notion_complete_fixer.py for comprehensive fixes

Focus on surgical solutions, not broad fixes.
```

### Documentation Enhancement
```
Please review this documentation for:
1. Clarity for AI assistant consumption
2. Step-by-step actionability
3. Real-world example inclusion
4. Professional presentation
5. Session continuity integration

Maintain our systematic approach standards.
```

### Implementation Gap Detection
```
I see the system is designed to [specific behavior]. If it were working correctly, wouldn't we see [expected evidence]? 

Let's validate whether our design matches our implementation:
- What should be happening automatically?
- What requires manual intervention?
- How can we test this recursively?

Focus on reality vs. aspiration.
```

### Payload Tax Analysis
```
We've designed [systematic approach] but I'm concerned about computational overhead. Let's analyze:
- What are the actual token/processing costs?
- What's the critical threshold for net benefit?
- Could we use a "session lens" approach to focus scope?
- How do we measure efficiency gains?

Calculate real costs vs. theoretical benefits.
```

### Timeline Reality Check
```
You suggested [timeframe] for [task]. Could we do this faster?
- What's the simplest version that works?
- Are we overcomplicating the approach?
- Can we iterate quickly rather than plan extensively?

Challenge complexity assumptions and bias toward rapid execution.
```

### Expert Intuition Validation
```
I have a suspicion about [specific issue]. My intuition is [hypothesis].
- Can we test this specific theory first?
- Should we ignore obvious symptoms and focus on root cause?
- How do we validate with real data rather than artificial examples?

Use surgical approach based on domain expertise.
```

---

*Add new prompts as they prove effective in real collaboration scenarios.* 